{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Parent.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# dfProduct = pd.read_csv(\"Product.csv\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dfParent \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mParent.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m dfOrder \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mOrder.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m dfReqStockoutProductDetail \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mReqStockoutProductDetail.csv\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# Request Stockout Product Detail\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown engine: \u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m (valid options are \u001b[39m\u001b[39m{\u001b[39;00mmapping\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mreturn\u001b[39;00m mapping[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[39m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open_handles(src, kwds)\n\u001b[1;32m     52\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_handles\u001b[39m(\u001b[39mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m    223\u001b[0m         src,\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    225\u001b[0m         encoding\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    226\u001b[0m         compression\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    227\u001b[0m         memory_map\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    228\u001b[0m         storage_options\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    229\u001b[0m         errors\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    230\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    703\u001b[0m             handle,\n\u001b[1;32m    704\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    705\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    706\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    707\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    708\u001b[0m         )\n\u001b[1;32m    709\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Parent.csv'"
     ]
    }
   ],
   "source": [
    "dfChild = pd.read_csv(\"Child.csv\")\n",
    "dfParent = pd.read_csv(\"Parent.csv\")\n",
    "dfOrder = pd.read_csv(\"Order.csv\")\n",
    "\n",
    "dfReqStockoutProductDetail = pd.read_csv(\"ReqStockoutProductDetail.csv\") # Request Stockout Product Detail\n",
    "dfOutSourcingDetail = pd.read_csv(\"OutSourcingDetail.csv\") # Outsourcing Detail\n",
    "dfReturnProduct = pd.read_csv(\"ReturnProduct.csv\") # Return Product\n",
    "dfPurchaseOrder = pd.read_csv(\"PurchaseOrder.csv\") # Purchase Order\n",
    "dfStockInPurchaseOrder = pd.read_csv(\"StockInPurchaseOrder.csv\") # Purchase Order\n",
    "dfOutSourcingQuota = pd.read_csv(\"OutSourcingQuota.csv\")\n",
    "# dfOutSourcing = pd.read_csv(\"OutSourcing.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutSourcingQuota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutSourcingQuota.merge(dfChild , left_on = 'product_id' , right_on= 'parent_product' , how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild[dfChild['child_product'] == 84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPurchaseOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStockInPurchaseOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPurchaseOrder = dfPurchaseOrder.merge(dfStockInPurchaseOrder,on = 'product_id' , how = 'outer')\n",
    "dfPurchaseOrder = dfPurchaseOrder.replace(np.nan, 0)\n",
    "dfPurchaseOrder[\"material_not_in_stock\"] = dfPurchaseOrder[\"purchase_order_quantity\"] - dfPurchaseOrder['quantity_in_stock_purchase_order']\n",
    "dfPurchaseOrder[dfPurchaseOrder['material_not_in_stock'] < 0] = 0\n",
    "dfPurchaseOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReturnProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent.loc[dfParent['parent_product'] == 8422]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder_drop_dup = dfOrder.drop_duplicates(subset=['order_code', 'product_code'], keep='first').reset_index(drop= True)\n",
    "dfOrder_groupby_sum = dfOrder.groupby(['order_code', 'product_code'], as_index=False)['stockout_quantity'].sum()\n",
    "dfOrder_groupby_sum.sort_values(by = ['stockout_quantity'])\n",
    "dfOrder = pd.merge(dfOrder_drop_dup , dfOrder_groupby_sum, on=['order_code', 'product_code'], how='inner').drop(columns = ['stockout_quantity_x']).rename(columns = {\"stockout_quantity_y\":\"stockout_quantity\"})\n",
    "dfOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProductionOrder = dfOrder[['parent_product' , 'production_order_quantity', 'stockout_quantity']]\n",
    "dfProductionOrder.sort_values(by = ['parent_product'])\n",
    "dfProductionOrderDetail = dfProductionOrder.groupby(['parent_product'], as_index=False)['production_order_quantity' , 'stockout_quantity'].sum()\n",
    "dfProductionOrderDetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOutSourcingDetail.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfReqStockoutProductDetail.merge(dfOutSourcingDetail, on = 'product_id' , how = 'outer')\n",
    "df = df.merge(dfReturnProduct, on = 'product_id' , how = 'outer')\n",
    "df.rename(columns = {'product_id':'parent_product'}, inplace = True)\n",
    "df = dfProductionOrderDetail.merge(df, on = 'parent_product' , how = 'outer')\n",
    "df = dfParent.merge(df, on = 'parent_product' , how = 'outer').drop(columns = ['is_outsourcing'])\n",
    "df = df.fillna(0).reset_index(drop= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['parent_product'] == 3802]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_production_need'] =  df['production_order_quantity'] + df['quantity_req_stockout'] + df['outsourcing_quantity'] + df['return_request_quantity']\n",
    "df['total_exported'] = df['stockout_quantity'] + df['exported_req_quantity'] + df['quantity_stock_in'] + df['returned_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temporary_production_inventory'] =  df['product_quantity'] - (df['total_production_need'] - df['total_exported'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProductionNeedsAndExported = df\n",
    "dfProductionNeedsAndExported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent[dfParent['parent_product'] == 86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfParent.loc[dfParent['parent_product'] == 8422]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder.loc[dfOrder['order_code'] == \"NXK-BLACK-01295-VM-Gray-L-POJK3G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOrder_drop_dup = dfOrder.drop_duplicates(subset=['order_code', 'product_code'], keep='first').reset_index(drop= True)\n",
    "dfOrder_groupby_sum = dfOrder.groupby(['order_code', 'product_code'], as_index=False)['stockout_quantity'].sum()\n",
    "dfOrder_groupby_sum.sort_values(by = ['stockout_quantity'])\n",
    "dfOrder = pd.merge(dfOrder_drop_dup , dfOrder_groupby_sum, on=['order_code', 'product_code'], how='inner').drop(columns = ['stockout_quantity_x']).rename(columns = {\"stockout_quantity_y\":\"stockout_quantity\"})\n",
    "dfOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChild2 = dfChild.drop_duplicates(keep='first').reset_index(drop = True)\n",
    "dfChild2 = dfChild2.sort_values(by=['parent_product']).reset_index(drop = True)\n",
    "dfChild3 = pd.merge(dfChild2 , dfParent[['parent_product','product_quantity','temporary_quantity']], left_on='child_product', right_on='parent_product', how='inner').drop(columns = ['parent_product_y']).rename(columns = {\"parent_product_x\":\"parent_product\"})\n",
    "dfChild3 = dfChild3.reset_index(drop = True)\n",
    "g = dfChild3.groupby([\"parent_product\"]).cumcount().add(1)\n",
    "dfChildMerge = dfChild3.set_index([\"parent_product\", g]).unstack(fill_value=0).sort_index(axis=1, level=1)\n",
    "dfChildMerge.columns = [\"{}{}\".format(a, b) for a, b in dfChildMerge.columns]\n",
    "\n",
    "dfChildMerge = dfChildMerge.reset_index()\n",
    "\n",
    "dfChildMerge = dfChildMerge.replace(np.nan, 0)\n",
    "dfChildMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChildMerge[dfChildMerge['parent_product'] == 8522]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChildMerge[dfChildMerge['quota5'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeMaterialOrder(dfChild, dfParent, dfOrder):\n",
    "   dfChild2 = dfChild.drop_duplicates(keep='first').reset_index(drop = True)\n",
    "   dfChild2 = dfChild2.sort_values(by=['parent_product']).reset_index(drop = True)\n",
    "   dfChild3 = pd.merge(dfChild2 , dfParent[['parent_product','product_quantity','temporary_quantity']], left_on='child_product', right_on='parent_product', how='inner').drop(columns = ['parent_product_y']).rename(columns = {\"parent_product_x\":\"parent_product\"})\n",
    "   dfChild3 = dfChild3.reset_index(drop = True)\n",
    "   g = dfChild3.groupby([\"parent_product\"]).cumcount().add(1)\n",
    "   dfChildMerge = dfChild3.set_index([\"parent_product\", g]).unstack(fill_value=0).sort_index(axis=1, level=1)\n",
    "   dfChildMerge.columns = [\"{}{}\".format(a, b) for a, b in dfChildMerge.columns]\n",
    "\n",
    "   dfChildMerge = dfChildMerge.reset_index()\n",
    "\n",
    "   dfChildMerge = dfChildMerge.replace(np.nan, 0)\n",
    "   dfTotalMate = pd.merge(dfParent, dfChildMerge, on='parent_product', how='left')\n",
    "   dfTotalMate = dfTotalMate.replace(np.nan, 0)\n",
    "   \n",
    "   dfTotalMate = dfTotalMate.drop(dfTotalMate[(dfTotalMate['child_product1'] == 0) & (dfTotalMate['is_outsourcing'] == 1)].index).reset_index(drop = True)\n",
    "   new_col1 = ['parent_product','product_code' , 'product_quantity' ,'temporary_quantity', 'is_outsourcing', \n",
    "      'product_code1', 'child_product1', 'quota1',\n",
    "      'product_quantity1', 'temporary_quantity1', 'product_code2',\n",
    "      'child_product2', 'quota2', 'product_quantity2',\n",
    "      'temporary_quantity2', 'product_code3', 'child_product3', 'quota3',\n",
    "      'product_quantity3', 'temporary_quantity3', 'product_code4',\n",
    "      'child_product4', 'quota4', 'product_quantity4',\n",
    "      'temporary_quantity4', 'product_code5', 'child_product5', 'quota5',\n",
    "      'product_quantity5', 'temporary_quantity5']\n",
    "   \n",
    "   dfTotalMate= dfTotalMate.reindex(columns=new_col1)\n",
    "   dfTotalMate = dfTotalMate.sort_values(by= ['parent_product']).reset_index(drop = True) \n",
    "\n",
    "   dfTotal = pd.merge(dfOrder , dfTotalMate, left_on='product_code', right_on='product_code', how='left')\n",
    "   dfTotal = dfTotal.reset_index(drop = True)\n",
    "   new_col2 = ['order_code' , 'position' , 'total_quota', 'stockout_quantity',\n",
    "      'parent_product' , 'product_code' , 'product_quantity',\n",
    "      'temporary_quantity', 'is_outsourcing' , 'product_code1', 'child_product1', 'quota1',\n",
    "      'product_quantity1', 'temporary_quantity1', 'product_code2',\n",
    "      'child_product2', 'quota2', 'product_quantity2',\n",
    "      'temporary_quantity2', 'product_code3', 'child_product3', 'quota3',\n",
    "      'product_quantity3', 'temporary_quantity3', 'product_code4',\n",
    "      'child_product4', 'quota4', 'product_quantity4',\n",
    "      'temporary_quantity4', 'product_code5', 'child_product5', 'quota5',\n",
    "      'product_quantity5', 'temporary_quantity5']\n",
    "   \n",
    "   dfTotal=dfTotal.reindex(columns=new_col2)\n",
    "\n",
    "   dfTotal = dfTotal[:1000] \n",
    "   dfTotalReverse = dfTotal[::-1]\n",
    "   dfTotalReverse = dfTotalReverse.reset_index(drop = True)\n",
    "   dfTotalReverse = dfTotalReverse.drop(dfTotalReverse[np.isnan(dfTotalReverse['parent_product']) == True].index).reset_index(drop = True)\n",
    "   return dfTotalMate, dfTotalReverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalMate, dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "dfTotalMate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalReverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_evaluated = {\"order_code\":[] , \"position\":[], \"product_code\":[] ,  \"comment\" : [] ,\"total_quota\": [] , \n",
    "                  \"stockout_quantity\": [] , \"temporary_quantity\" : [] , \"lack_of_material\" : [] ,  \"quota\" : [] , \n",
    "                  \"lack_of_quantity\": [], \"is_outsourcing\" : []}\n",
    "listColMateTtReverse = [9,14,19,24,29]\n",
    "listColMate = [5,10,15,20,25] \n",
    "\n",
    "def updateDictEvaluated(dict_evaluated, aMate , comment, total_quota, stockout_quantity, \n",
    "                        temporary_quantity, lack_of_material, quota , lack_of_quantity , is_outsourcing):\n",
    "    dict_evaluated[\"order_code\"].append(aMate['order_code'])\n",
    "    dict_evaluated[\"position\"].append(aMate['position'])\n",
    "    dict_evaluated[\"product_code\"].append(aMate['product_code'])\n",
    "    dict_evaluated[\"comment\"].append(comment)\n",
    "    dict_evaluated[\"total_quota\"].append(total_quota)\n",
    "    dict_evaluated[\"stockout_quantity\"].append(stockout_quantity)\n",
    "    dict_evaluated[\"temporary_quantity\"].append(temporary_quantity)\n",
    "    dict_evaluated[\"lack_of_material\"].append(lack_of_material)\n",
    "    dict_evaluated[\"quota\"].append(quota)\n",
    "    dict_evaluated[\"lack_of_quantity\"].append(lack_of_quantity)\n",
    "    dict_evaluated[\"is_outsourcing\"].append(is_outsourcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calLevel1(ahat, total_missing_quota, dfParent):\n",
    "    sub = ahat['temporary_quantity'] - total_missing_quota\n",
    "    indexCode = dfParent[dfParent['product_code'] == ahat['product_code']].index[0] \n",
    "    dfParent.at[indexCode , 'temporary_quantity'] = sub\n",
    "    sub = np.round(sub, 2)\n",
    "    return sub, dfParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the quantity of material after using it\n",
    "def replaceNewValue(aMate, dfParent , sub):\n",
    "    update_sub = 0\n",
    "    for i in listColMate: \n",
    "        if(aMate[i] != 0):\n",
    "            indexCode = dfParent[dfParent['product_code'] == aMate[i]].index[0]\n",
    "            update_sub = aMate[i+4] + (sub / aMate[i+2])\n",
    "            dfParent.at[indexCode , 'temporary_quantity'] = round(update_sub,2)\n",
    "        else:\n",
    "            break\n",
    "    return dfParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalReverse.loc[dfTotalReverse[\"product_code\"] == \"5-DAFELT-BLK-07-TA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calLevel2(ahat , product_id, dfTotalMate , sub1 , sub , dict_evaluated, dfParent, dfTotalReverse , quota):\n",
    "    dict_notenough = {\"product_id\": [], \"index_min\": [] , \"quota\": [] ,\"quantity_product\": [] , \"temp_quantity\": []}\n",
    "    count = negative = positive = 0\n",
    "    aMate = dfTotalMate.loc[np.where(dfTotalMate['parent_product'] == product_id)[0][0]] \n",
    "    for i in listColMate: \n",
    "        if (aMate[5] == 0):\n",
    "            return updateDictEvaluated(dict_evaluated, ahat, \"not enough\", ahat['total_quota'] ,ahat['stockout_quantity'] ,sub1, aMate[i-4], quota , sub , 0)\n",
    "            \n",
    "        elif(aMate[i] != 0):\n",
    "            slSC = aMate[i+4] * aMate[i+2]\n",
    "            if((slSC + sub1) < 0):\n",
    "                dict_notenough['product_id'].append(aMate[i+1]) \n",
    "                dict_notenough['index_min'].append(i) \n",
    "                dict_notenough['quota'].append(quota * aMate[i+2]) \n",
    "                dict_notenough['quantity_product'].append(slSC) \n",
    "                dict_notenough['temp_quantity'].append(np.round((slSC + sub1)/aMate[i+2] , 2)) \n",
    "                negative = negative + 1\n",
    "            else:\n",
    "                positive = positive + 1\n",
    "            count = count + 1\n",
    "        else:\n",
    "            break\n",
    "                \n",
    "    df_notenough = pd.DataFrame(dict_notenough)\n",
    "        \n",
    "    dfParent = replaceNewValue(aMate, dfParent , sub)\n",
    "    dfTotalMate,dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "    \n",
    "    if(count == positive):\n",
    "        return updateDictEvaluated(dict_evaluated, ahat, \"enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub1, np.NaN, quota , np.NaN, np.NaN)    \n",
    "    else:    \n",
    "        for i in range(0, negative):\n",
    "            return calLevel2(ahat, df_notenough.loc[i]['product_id'], dfTotalMate , sub1, df_notenough.loc[i]['temp_quantity'], dict_evaluated, dfParent, dfTotalReverse, df_notenough.loc[i]['quota'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary(dfTotalReverse , dfParent, dfTotalMate, index):\n",
    "    ahat = dfTotalReverse.loc[index]\n",
    "    total_missing_quota = ahat['total_quota'] - ahat['stockout_quantity'] \n",
    "    if(total_missing_quota <= 0.0):\n",
    "        updateDictEvaluated(dict_evaluated, ahat, \"exported\", ahat['total_quota'] , ahat['stockout_quantity'], np.NAN, np.NAN , np.NAN , np.NAN, np.NAN)\n",
    "    else: \n",
    "        if(ahat['is_outsourcing'] == 0):\n",
    "            sub, dfParent = calLevel1(ahat, total_missing_quota, dfParent)\n",
    "            dfTotalMate,dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "            if(sub > 0):\n",
    "                updateDictEvaluated(dict_evaluated, ahat, \"enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub, np.NAN, np.NAN, np.NAN , 0)\n",
    "            else:\n",
    "                updateDictEvaluated(dict_evaluated, ahat, \"not enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub , ahat[\"product_code\"],np.NAN, sub , 0)\n",
    "        else:\n",
    "            sub1, dfParent = calLevel1(ahat, total_missing_quota, dfParent)\n",
    "            sub = np.NAN\n",
    "            dfTotalMate,dfTotalReverse = mergeMaterialOrder(dfChild , dfParent, dfOrder)\n",
    "            if(sub1 > 0):\n",
    "                updateDictEvaluated(dict_evaluated, ahat, \"enough\", ahat['total_quota'] , ahat['stockout_quantity'], sub1 , np.NAN,  np.NAN, np.NAN , 1)\n",
    "            else:\n",
    "                calLevel2(ahat , ahat['parent_product'], dfTotalMate , sub1 , sub , dict_evaluated, dfParent, dfTotalReverse , 1)\n",
    "    return dfTotalMate, dfTotalReverse\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalReverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(dfTotalReverse)):\n",
    "    dfTotalMate, dfTotalReverse = primary(dfTotalReverse ,dfParent, dfTotalMate, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEvaluted = pd.DataFrame.from_dict(dict_evaluated)\n",
    "# dfEvaluted = dfEvaluted[::-1].reset_index(drop = True)\n",
    "dfEvaluted.to_excel('data.xlsx')\n",
    "dfEvaluted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOrder = dfEvaluted['order_code'].unique()\n",
    "newDictEvalue = {\"order_code\": [] , \"comment\": []}\n",
    "for i in listOrder:\n",
    "    listEva = dfEvaluted.loc[dfEvaluted['order_code'] == i]['comment'].unique()\n",
    "    if (len(listEva) == 1):\n",
    "        newDictEvalue[\"comment\"].append(listEva[0])\n",
    "        newDictEvalue[\"order_code\"].append(i)\n",
    "    else:\n",
    "        if(listEva[0] != listEva[1]):\n",
    "            newDictEvalue[\"comment\"].append(\"not enough\")\n",
    "            newDictEvalue[\"order_code\"].append(i)\n",
    "        else:\n",
    "            newDictEvalue[\"comment\"].append(listEva)\n",
    "        \n",
    "dfEvalutedTt = pd.DataFrame.from_dict(newDictEvalue)\n",
    "# dfEvalutedTt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfEvalutedTt.loc[dfEvalutedTt[\"quantity\"] == \"enough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfEvalutedTt.loc[dfEvalutedTt[\"quantity\"] == \"not enough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
